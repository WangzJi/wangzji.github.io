---
layout: post
title: "Hadoop å®Œå…¨æŒ‡å—ï¼ˆä¸€ï¼‰ï¼šä»é›¶å¼€å§‹æ·±å…¥ç†è§£å¤§æ•°æ®ç”Ÿæ€æ ¸å¿ƒåŸºåº§"
date: 2026-01-12
category: backend
tags: [Hadoop, Big Data, Distributed Systems, Java]
excerpt: "ä» 0 åˆ° 1 æ·±å…¥è§£æ Hadoop æ ¸å¿ƒæ¶æ„ï¼Œæ¶µç›– HDFSã€YARNã€MapReduce è¿è¡ŒåŸç†ä¸ç”Ÿäº§å®è·µç»éªŒã€‚"
read_time: "35 min read"
---

# Hadoop å®Œå…¨æŒ‡å—ï¼ˆä¸€ï¼‰ï¼šä»é›¶å¼€å§‹æ·±å…¥ç†è§£å¤§æ•°æ®ç”Ÿæ€æ ¸å¿ƒåŸºåº§

> æœ¬æ–‡å°†å¸¦ä½ ä»é›¶å¼€å§‹ç³»ç»Ÿå­¦ä¹  Hadoop ç”Ÿæ€ç³»ç»Ÿï¼Œæ¶µç›–å…¶è¯ç”ŸèƒŒæ™¯ã€æ ¸å¿ƒæ¶æ„ã€å…³é”®ç»„ä»¶ã€åº”ç”¨åœºæ™¯ä»¥åŠå®è·µå»ºè®®ã€‚æ— è®ºä½ æ˜¯å¤§æ•°æ®åˆå­¦è€…è¿˜æ˜¯å¸Œæœ›æ·±å…¥ç†è§£ Hadoop å†…éƒ¨æœºåˆ¶çš„å¼€å‘è€…ï¼Œæœ¬æ–‡éƒ½å°†ä¸ºä½ æä¾›ä¸€ä¸ªæ¸…æ™°çš„å­¦ä¹ è·¯å¾„ã€‚

---

## ä¸€ã€Hadoop è¯ç”ŸèƒŒæ™¯ï¼šå¤§æ•°æ®æ—¶ä»£çš„æŒ‘æˆ˜

### 1. ä¼ ç»Ÿå­˜å‚¨ä¸è®¡ç®—çš„ç“¶é¢ˆ

åœ¨ 21 ä¸–çºªåˆï¼Œéšç€äº’è”ç½‘çš„çˆ†ç‚¸å¼å¢é•¿ï¼Œä¼ä¸šé¢ä¸´ç€å‰æ‰€æœªæœ‰çš„æ•°æ®æŒ‘æˆ˜ï¼š

| æŒ‘æˆ˜ | ä¼ ç»Ÿæ–¹æ¡ˆ | é—®é¢˜ |
|------|---------|------|
| **æµ·é‡æ•°æ®å­˜å‚¨** | å•æœºç£ç›˜ã€SAN/NAS | æˆæœ¬é«˜æ˜‚ï¼Œæ‰©å±•å›°éš¾ |
| **æ•°æ®å¤„ç†é€Ÿåº¦** | å•æœº CPU è®¡ç®— | å¤„ç†æ—¶é—´éšæ•°æ®é‡çº¿æ€§å¢é•¿ |
| **ç³»ç»Ÿå¯é æ€§** | RAIDã€å¤‡ä»½ | ç¡¬ä»¶æ•…éšœå¯¼è‡´æœåŠ¡ä¸­æ–­ |
| **æˆæœ¬å‹åŠ›** | é«˜ç«¯æœåŠ¡å™¨ | ROI ä½ï¼Œç»´æŠ¤æˆæœ¬é«˜ |

### 2. Google çš„ä¸‰é©¾é©¬è½¦

2003-2006 å¹´ï¼ŒGoogle å‘å¸ƒäº†ä¸‰ç¯‡å¥ åŸºæ€§è®ºæ–‡ï¼Œå¼€å¯äº†å¤§æ•°æ®æ—¶ä»£ï¼š

```mermaid
timeline
    title Google å¤§æ•°æ®æŠ€æœ¯æ¼”è¿›
    2003 : GFS (Google File System)
         : åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ
    2004 : MapReduce
         : åˆ†å¸ƒå¼è®¡ç®—æ¡†æ¶
    2006 : Bigtable
         : åˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿ
```

### 3. Hadoop çš„è¯ç”Ÿ

**Doug Cutting**ï¼ˆLucene åˆ›å§‹äººï¼‰å’Œ **Mike Cafarella** åœ¨å¼€å‘æœç´¢å¼•æ“ Nutch æ—¶ï¼Œå€Ÿé‰´ Google çš„è®ºæ–‡ï¼Œäº **2006 å¹´** åˆ›å»ºäº† Hadoop é¡¹ç›®ï¼Œå¹¶äº **2008 å¹´** æˆä¸º Apache é¡¶çº§é¡¹ç›®ã€‚

**åå­—ç”±æ¥**ï¼šHadoop æ¥è‡ª Doug Cutting å„¿å­çš„ç©å…·å¤§è±¡çš„åå­— ğŸ˜

---

## äºŒã€Hadoop æ ¸å¿ƒæ¶æ„æ¦‚è§ˆ

Hadoop æ˜¯ä¸€ä¸ª**åˆ†å¸ƒå¼ç³»ç»ŸåŸºç¡€æ¶æ„**ï¼Œç”± Apache åŸºé‡‘ä¼šå¼€å‘ï¼Œä¸»è¦è§£å†³**æµ·é‡æ•°æ®çš„å­˜å‚¨ä¸è®¡ç®—**é—®é¢˜ã€‚

### 1. æ ¸å¿ƒç»„ä»¶æ¶æ„

```mermaid
graph TB
    subgraph HadoopCore["Hadoop Core"]
        HDFS["HDFS<br/>åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ"]
        YARN["YARN<br/>èµ„æºç®¡ç†å™¨"]
        MapReduce["MapReduce<br/>åˆ†å¸ƒå¼è®¡ç®—æ¡†æ¶"]
    end
    
    subgraph StorageLayer["Storage Layer"]
        NameNode["NameNode<br/>å…ƒæ•°æ®ç®¡ç†"]
        DataNode1["DataNode 1"]
        DataNode2["DataNode 2"]
        DataNode3["DataNode N"]
    end
    
    subgraph ComputingLayer["Computing Layer"]
        ResourceManager["ResourceManager<br/>èµ„æºè°ƒåº¦"]
        NodeManager1["NodeManager 1"]
        NodeManager2["NodeManager 2"]
        NodeManager3["NodeManager N"]
    end
    
    HDFS -.-> NameNode
    NameNode --> DataNode1
    NameNode --> DataNode2
    NameNode --> DataNode3
    
    YARN -.-> ResourceManager
    ResourceManager --> NodeManager1
    ResourceManager --> NodeManager2
    ResourceManager --> NodeManager3
    
    MapReduce --> YARN
    MapReduce --> HDFS
```

### 2. ä¸‰å¤§æ ¸å¿ƒç»„ä»¶

| ç»„ä»¶ | å…¨ç§° | æ ¸å¿ƒåŠŸèƒ½ | ç±»æ¯” |
|------|------|----------|------|
| **HDFS** | Hadoop Distributed File System | åˆ†å¸ƒå¼æ–‡ä»¶å­˜å‚¨ | å¤§æ•°æ®çš„"ç¡¬ç›˜" |
| **YARN** | Yet Another Resource Negotiator | èµ„æºç®¡ç†ä¸è°ƒåº¦ | å¤§æ•°æ®çš„"æ“ä½œç³»ç»Ÿ" |
| **MapReduce** | Map + Reduce | åˆ†å¸ƒå¼å¹¶è¡Œè®¡ç®— | å¤§æ•°æ®çš„"ç¼–ç¨‹æ¨¡å‹" |

---

## ä¸‰ã€HDFSï¼šåˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿè¯¦è§£

### 1. HDFS è®¾è®¡ç†å¿µ

HDFS çš„è®¾è®¡åŸºäºä»¥ä¸‹æ ¸å¿ƒå‡è®¾ï¼š

> [!IMPORTANT]
> **HDFS çš„æ ¸å¿ƒè®¾è®¡åŸåˆ™**
> - **ç¡¬ä»¶æ•…éšœæ˜¯å¸¸æ€**ï¼šç³»ç»Ÿå¿…é¡»èƒ½è‡ªåŠ¨æ£€æµ‹å’Œæ¢å¤
> - **æµå¼æ•°æ®è®¿é—®**ï¼šä¸€æ¬¡å†™å…¥ï¼Œå¤šæ¬¡è¯»å–
> - **å¤§æ•°æ®é›†**ï¼šæ”¯æŒ GB/TB/PB çº§åˆ«çš„æ–‡ä»¶
> - **ç®€å•ä¸€è‡´æ€§æ¨¡å‹**ï¼šä¸€æ¬¡å†™å…¥ï¼Œä¸æ”¯æŒéšæœºä¿®æ”¹
> - **ç§»åŠ¨è®¡ç®—æ¯”ç§»åŠ¨æ•°æ®æ›´åˆ’ç®—**ï¼šè®¡ç®—å‘æ•°æ®é æ‹¢

### 2. HDFS æ¶æ„è¯¦è§£

```mermaid
graph TB
    Client[HDFS Client]
    
    subgraph Master
        NN[NameNode<br/>ä¸»èŠ‚ç‚¹]
        SNN[Secondary NameNode<br/>è¾…åŠ©èŠ‚ç‚¹]
    end
    
    subgraph Slaves
        DN1[DataNode 1<br/>Block 1, 3, 5]
        DN2[DataNode 2<br/>Block 1, 2, 4]
        DN3[DataNode 3<br/>Block 2, 3, 4]
    end
    
    Client -->|1. è¯·æ±‚æ–‡ä»¶å…ƒæ•°æ®| NN
    NN -->|2. è¿”å› Block ä½ç½®åˆ—è¡¨| Client
    Client -->|3. ç›´æ¥è¯»å†™æ•°æ®| DN1
    Client -->|3. ç›´æ¥è¯»å†™æ•°æ®| DN2
    Client -->|3. ç›´æ¥è¯»å†™æ•°æ®| DN3
    
    DN1 -->|å¿ƒè·³ + å—æŠ¥å‘Š| NN
    DN2 -->|å¿ƒè·³ + å—æŠ¥å‘Š| NN
    DN3 -->|å¿ƒè·³ + å—æŠ¥å‘Š| NN
    
    NN -.->|å®šæœŸåˆå¹¶ fsimage + editlog| SNN
```

#### 2.1 NameNodeï¼ˆåç§°èŠ‚ç‚¹ï¼‰

**èŒè´£**ï¼šç®¡ç†æ–‡ä»¶ç³»ç»Ÿçš„å‘½åç©ºé—´å’Œå…ƒæ•°æ®

**æ ¸å¿ƒæ•°æ®ç»“æ„**ï¼š

```java
// æ–‡ä»¶ç³»ç»Ÿæ ‘ï¼ˆå†…å­˜ä¸­ï¼‰
FSDirectory
  â”œâ”€â”€ FSNamesystemï¼ˆå‘½åç©ºé—´ï¼‰
  â”œâ”€â”€ INodeTreeï¼ˆæ–‡ä»¶/ç›®å½•æ ‘ï¼‰
  â””â”€â”€ BlockManagerï¼ˆå—ç®¡ç†å™¨ï¼‰

// æŒä¹…åŒ–æ•°æ®
FsImage         // å‘½åç©ºé—´é•œåƒï¼ˆå®šæœŸå¿«ç…§ï¼‰
EditLog         // æ“ä½œæ—¥å¿—ï¼ˆå®æ—¶å†™å…¥ï¼‰
```

**å…ƒæ•°æ®ç¤ºä¾‹**ï¼š

```
æ–‡ä»¶è·¯å¾„: /user/hadoop/test.txt
  â”œâ”€â”€ æ–‡ä»¶å¤§å°: 300MB
  â”œâ”€â”€ å‰¯æœ¬æ•°: 3
  â”œâ”€â”€ å—å¤§å°: 128MB
  â”œâ”€â”€ å—åˆ—è¡¨:
  â”‚     â”œâ”€â”€ Block_1 (128MB) â†’ [DN1, DN2, DN3]
  â”‚     â”œâ”€â”€ Block_2 (128MB) â†’ [DN2, DN3, DN4]
  â”‚     â””â”€â”€ Block_3 (44MB)  â†’ [DN1, DN3, DN5]
  â””â”€â”€ æƒé™: rwxr-xr-x
```

> [!WARNING]
> **NameNode æ˜¯å•ç‚¹æ•…éšœ (SPOF)**
> 
> åœ¨ Hadoop 1.x ä¸­ï¼ŒNameNode æŒ‚æ‰ä¼šå¯¼è‡´æ•´ä¸ªé›†ç¾¤ä¸å¯ç”¨ã€‚Hadoop 2.x å¼•å…¥äº† **NameNode HAï¼ˆé«˜å¯ç”¨ï¼‰** æœºåˆ¶ï¼Œé€šè¿‡ä¸»å¤‡æ¨¡å¼è§£å†³æ­¤é—®é¢˜ã€‚

#### 2.2 DataNodeï¼ˆæ•°æ®èŠ‚ç‚¹ï¼‰

**èŒè´£**ï¼šå­˜å‚¨å’Œç®¡ç†å®é™…çš„æ•°æ®å—

**å·¥ä½œæµç¨‹**ï¼š

```mermaid
sequenceDiagram
    participant DN as DataNode
    participant NN as NameNode
    
    Note over DN: å¯åŠ¨
    DN->>NN: 1. æ³¨å†Œï¼ˆç‰ˆæœ¬å·ã€å­˜å‚¨IDï¼‰
    NN->>DN: 2. ç¡®è®¤æ³¨å†Œ
    
    loop æ¯3ç§’
        DN->>NN: 3. å‘é€å¿ƒè·³
        NN->>DN: 4. è¿”å›æŒ‡ä»¤ï¼ˆå¤åˆ¶ã€åˆ é™¤ç­‰ï¼‰
    end
    
    loop æ¯6å°æ—¶
        DN->>NN: 5. å‘é€å—æŠ¥å‘Šï¼ˆæ‰€æœ‰å—åˆ—è¡¨ï¼‰
        NN->>DN: 6. ç¡®è®¤
    end
```

**DataNode å­˜å‚¨ç»“æ„**ï¼š

```
/data/hadoop/dfs/data/
  â””â”€â”€ current/
      â”œâ”€â”€ BP-xxxx-NameNode-xxx/
      â”‚   â””â”€â”€ current/
      â”‚       â””â”€â”€ finalized/
      â”‚           â”œâ”€â”€ blk_1073741825        # æ•°æ®å—æ–‡ä»¶
      â”‚           â”œâ”€â”€ blk_1073741825.meta   # å…ƒæ•°æ®æ–‡ä»¶ï¼ˆæ ¡éªŒå’Œï¼‰
      â”‚           â”œâ”€â”€ blk_1073741826
      â”‚           â””â”€â”€ blk_1073741826.meta
      â””â”€â”€ VERSION
```

#### 2.3 Secondary NameNodeï¼ˆè¾…åŠ©èŠ‚ç‚¹ï¼‰

> [!CAUTION]
> **å¸¸è§è¯¯è§£**ï¼šSecondary NameNode ä¸æ˜¯ NameNode çš„å¤‡ä»½ï¼

**çœŸå®èŒè´£**ï¼šå®šæœŸåˆå¹¶ FsImage å’Œ EditLogï¼Œå‡è½» NameNode è´Ÿæ‹…

**å·¥ä½œæµç¨‹**ï¼š

```mermaid
sequenceDiagram
    participant SNN as Secondary NameNode
    participant NN as NameNode
    
    loop æ¯å°æ—¶ï¼ˆå¯é…ç½®ï¼‰
        SNN->>NN: 1. è¯·æ±‚åˆå¹¶æ£€æŸ¥ç‚¹
        NN->>SNN: 2. å‘é€ fsimage + editlog
        Note over SNN: 3. åˆå¹¶ç”Ÿæˆæ–° fsimage.ckpt
        SNN->>NN: 4. ä¼ å›æ–°çš„ fsimage
        Note over NN: 5. æ›¿æ¢æ—§ fsimageï¼Œæ¸…ç©º editlog
    end
```

### 3. HDFS æ•°æ®è¯»å†™æµç¨‹

#### 3.1 å†™å…¥æµç¨‹ï¼ˆè¯¦ç»†ç‰ˆï¼‰

```mermaid
sequenceDiagram
    participant Client
    participant NN as NameNode
    participant DN1 as DataNode 1
    participant DN2 as DataNode 2
    participant DN3 as DataNode 3
    
    Client->>NN: 1. åˆ›å»ºæ–‡ä»¶è¯·æ±‚
    NN->>Client: 2. ç¡®è®¤å¯åˆ›å»º
    
    Client->>NN: 3. è¯·æ±‚å†™å…¥ç¬¬ä¸€ä¸ª Block
    Note over NN: 4. é€‰æ‹© 3 ä¸ª DataNode<br/>ï¼ˆæœºæ¶æ„ŸçŸ¥ç­–ç•¥ï¼‰
    NN->>Client: 5. è¿”å› DN åˆ—è¡¨ [DN1, DN2, DN3]
    
    Client->>DN1: 6. å»ºç«‹ Pipelineï¼ˆDN1â†’DN2â†’DN3ï¼‰
    DN1->>DN2: 7. è¿æ¥ DN2
    DN2->>DN3: 8. è¿æ¥ DN3
    DN3->>DN2: 9. ACK
    DN2->>DN1: 10. ACK
    DN1->>Client: 11. Pipeline å»ºç«‹æˆåŠŸ
    
    loop æ•°æ®åŒ…ä¼ è¾“ï¼ˆ64KB/åŒ…ï¼‰
        Client->>DN1: 12. å‘é€æ•°æ®åŒ…
        DN1->>DN2: 13. è½¬å‘æ•°æ®åŒ…
        DN2->>DN3: 14. è½¬å‘æ•°æ®åŒ…
        DN3->>DN2: 15. ACK
        DN2->>DN1: 16. ACK
        DN1->>Client: 17. ACK
    end
    
    Client->>NN: 18. å…³é—­æ–‡ä»¶
    Note over NN: 19. æ›´æ–°å…ƒæ•°æ®ï¼Œæ ‡è®°å®Œæˆ
```

**æœºæ¶æ„ŸçŸ¥ç­–ç•¥**ï¼ˆé»˜è®¤å‰¯æœ¬æ”¾ç½®ç­–ç•¥ï¼‰ï¼š

```
å‰¯æœ¬1ï¼šClient æ‰€åœ¨èŠ‚ç‚¹ï¼ˆæˆ–åŒæœºæ¶éšæœºèŠ‚ç‚¹ï¼‰
å‰¯æœ¬2ï¼šä¸åŒæœºæ¶çš„éšæœºèŠ‚ç‚¹
å‰¯æœ¬3ï¼šä¸å‰¯æœ¬2 åŒæœºæ¶çš„ä¸åŒèŠ‚ç‚¹

ç¤ºä¾‹ï¼š
Rack1:       Rack2:
  DN1 âœ“        DN3 âœ“
  DN2 âœ“        DN4
```

#### 3.2 è¯»å–æµç¨‹ï¼ˆè¯¦ç»†ç‰ˆï¼‰

```mermaid
sequenceDiagram
    participant Client
    participant NN as NameNode
    participant DN as DataNode
    
    Client->>NN: 1. æ‰“å¼€æ–‡ä»¶è¯·æ±‚
    Note over NN: 2. æ£€æŸ¥æƒé™ã€æŸ¥æ‰¾å—ä½ç½®
    NN->>Client: 3. è¿”å› Block ä½ç½®åˆ—è¡¨<br/>[Block1â†’[DN1,DN2,DN3],<br/> Block2â†’[DN2,DN3,DN4]]
    
    loop è¯»å–æ¯ä¸ª Block
        Note over Client: 4. é€‰æ‹©æœ€è¿‘çš„ DataNode
        Client->>DN: 5. è¯·æ±‚è¯»å– Block1
        DN->>Client: 6. è¿”å›æ•°æ®
        Note over Client: 7. æ ¡éªŒæ•°æ®å®Œæ•´æ€§ï¼ˆCRCï¼‰
        alt æ ¡éªŒå¤±è´¥
            Client->>NN: 8. æŠ¥å‘ŠæŸåå—
            Note over Client: 9. å°è¯•ä»å…¶ä»–å‰¯æœ¬è¯»å–
        end
    end
    
    Client->>NN: 10. å…³é—­æ–‡ä»¶
```

**ç½‘ç»œæ‹“æ‰‘è·ç¦»è®¡ç®—**ï¼š

```
è·ç¦» = ä¸¤ä¸ªèŠ‚ç‚¹åˆ°æœ€è¿‘å…±åŒç¥–å…ˆçš„è·ç¦»ä¹‹å’Œ

åŒä¸€èŠ‚ç‚¹:      distance = 0
åŒä¸€æœºæ¶:      distance = 2
åŒä¸€æ•°æ®ä¸­å¿ƒ:   distance = 4
ä¸åŒæ•°æ®ä¸­å¿ƒ:   distance = 6

ç¤ºä¾‹ï¼š
/datacenter1/rack1/node1
/datacenter1/rack1/node2  â†’ distance = 2
/datacenter1/rack2/node3  â†’ distance = 4
```

### 4. HDFS ç‰¹æ€§æ€»ç»“

| ç‰¹æ€§ | ä¼˜åŠ¿ | å±€é™æ€§ |
|------|------|--------|
| **é«˜å®¹é”™** | æ•°æ®è‡ªåŠ¨å¤šå‰¯æœ¬ï¼Œç¡¬ä»¶æ•…éšœè‡ªåŠ¨æ¢å¤ | å­˜å‚¨å¼€é”€å¤§ï¼ˆ3å€ï¼‰ |
| **é«˜åå** | é€‚åˆæ‰¹å¤„ç†ï¼ŒGB/s çº§åˆ«åå | ä¸é€‚åˆä½å»¶è¿Ÿè®¿é—® |
| **å¤§æ–‡ä»¶** | æ”¯æŒ PB çº§å•æ–‡ä»¶ | å°æ–‡ä»¶ä¼šæ¶ˆè€—å¤§é‡ NameNode å†…å­˜ |
| **æµå¼è®¿é—®** | é¡ºåºè¯»å†™æ€§èƒ½ä¼˜ç§€ | ä¸æ”¯æŒéšæœºå†™ã€æ–‡ä»¶ä¿®æ”¹ |
| **å¯æ‰©å±•** | çº¿æ€§æ‰©å±•åˆ°æ•°åƒèŠ‚ç‚¹ | NameNode å†…å­˜æ˜¯ç“¶é¢ˆ |

---

## å››ã€YARNï¼šèµ„æºç®¡ç†ä¸è°ƒåº¦

### 1. YARN è¯ç”ŸèƒŒæ™¯

åœ¨ Hadoop 1.x ä¸­ï¼ŒMapReduce æ—¢è´Ÿè´£èµ„æºç®¡ç†åˆè´Ÿè´£ä»»åŠ¡è°ƒåº¦ï¼Œå¯¼è‡´ï¼š
- **å•ç‚¹æ•…éšœ**ï¼šJobTracker æŒ‚æ‰æ•´ä¸ªé›†ç¾¤ä¸å¯ç”¨
- **æ‰©å±•æ€§å·®**ï¼šæ— æ³•æ”¯æŒè¶…è¿‡ 4000 èŠ‚ç‚¹
- **èµ„æºåˆ©ç”¨ç‡ä½**ï¼šMap/Reduce Slot å›ºå®šåˆ†é…ï¼Œæµªè´¹ä¸¥é‡
- **åªæ”¯æŒ MapReduce**ï¼šæ— æ³•è¿è¡Œå…¶ä»–è®¡ç®—æ¡†æ¶

**è§£å†³æ–¹æ¡ˆ**ï¼šHadoop 2.0 å¼•å…¥ YARNï¼Œå®ç°**è®¡ç®—ä¸èµ„æºç®¡ç†åˆ†ç¦»**

### 2. YARN æ¶æ„

```mermaid
graph TB
    Client["Client å®¢æˆ·ç«¯"]
    
    subgraph YARNCluster["YARN Cluster"]
        RM["ResourceManager<br/>å…¨å±€èµ„æºç®¡ç†"]
        
        subgraph Node1["Node 1"]
            NM1["NodeManager"]
            C1["Container 1"]
            C2["Container 2"]
        end
        
        subgraph Node2["Node 2"]
            NM2["NodeManager"]
            AM["ApplicationMaster<br/>åº”ç”¨ç®¡ç†å™¨"]
            C3["Container 3"]
        end
        
        subgraph Node3["Node 3"]
            NM3["NodeManager"]
            C4["Container 4"]
            C5["Container 5"]
        end
    end
    
    Client -->|1. æäº¤åº”ç”¨| RM
    RM -->|2. å¯åŠ¨ AM| NM2
    AM -->|3. ç”³è¯·èµ„æº| RM
    RM -->|4. åˆ†é… Container| NM1
    RM -->|4. åˆ†é… Container| NM3
    AM -->|5. å¯åŠ¨ä»»åŠ¡| C1
    AM -->|5. å¯åŠ¨ä»»åŠ¡| C4
```

### 3. YARN æ ¸å¿ƒç»„ä»¶

#### 3.1 ResourceManagerï¼ˆèµ„æºç®¡ç†å™¨ï¼‰

**èŒè´£**ï¼šå…¨å±€èµ„æºè°ƒåº¦å’Œç®¡ç†

**æ ¸å¿ƒæ¨¡å—**ï¼š

```java
ResourceManager
  â”œâ”€â”€ ResourceScheduler        // èµ„æºè°ƒåº¦å™¨
  â”‚     â”œâ”€â”€ FIFO Scheduler      // å…ˆè¿›å…ˆå‡º
  â”‚     â”œâ”€â”€ Capacity Scheduler  // å®¹é‡è°ƒåº¦å™¨ï¼ˆé»˜è®¤ï¼‰
  â”‚     â””â”€â”€ Fair Scheduler      // å…¬å¹³è°ƒåº¦å™¨
  â”‚
  â”œâ”€â”€ ApplicationsManager      // åº”ç”¨ç®¡ç†
  â”‚     â”œâ”€â”€ æ¥æ”¶ä½œä¸šæäº¤
  â”‚     â”œâ”€â”€ å¯åŠ¨ ApplicationMaster
  â”‚     â””â”€â”€ å¤±è´¥é‡å¯
  â”‚
  â””â”€â”€ ResourceTrackerService   // èŠ‚ç‚¹ç®¡ç†
        â”œâ”€â”€ æ¥æ”¶ NodeManager å¿ƒè·³
        â””â”€â”€ ç»´æŠ¤èŠ‚ç‚¹çŠ¶æ€
```

#### 3.2 NodeManagerï¼ˆèŠ‚ç‚¹ç®¡ç†å™¨ï¼‰

**èŒè´£**ï¼šå•èŠ‚ç‚¹èµ„æºç®¡ç†å’Œä»»åŠ¡æ‰§è¡Œ

**åŠŸèƒ½**ï¼š
- å®šæœŸå‘ ResourceManager æ±‡æŠ¥èŠ‚ç‚¹çŠ¶æ€
- æ¥æ”¶å¹¶æ‰§è¡Œæ¥è‡ª ApplicationMaster çš„ä»»åŠ¡
- ç®¡ç† Container ç”Ÿå‘½å‘¨æœŸ
- ç›‘æ§èµ„æºä½¿ç”¨ï¼ˆCPUã€å†…å­˜ï¼‰

#### 3.3 ApplicationMasterï¼ˆåº”ç”¨ç®¡ç†å™¨ï¼‰

**èŒè´£**ï¼šå•ä¸ªåº”ç”¨çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼ˆæ¯ä¸ªåº”ç”¨ä¸€ä¸ªï¼‰

**åŠŸèƒ½**ï¼š
- å‘ ResourceManager ç”³è¯·èµ„æº
- ä¸ NodeManager é€šä¿¡å¯åŠ¨ Container
- ç›‘æ§ä»»åŠ¡çŠ¶æ€ï¼Œå¤„ç†å¤±è´¥é‡è¯•
- ä»»åŠ¡å®Œæˆåé‡Šæ”¾èµ„æº

#### 3.4 Containerï¼ˆå®¹å™¨ï¼‰

**å®šä¹‰**ï¼šèµ„æºæŠ½è±¡ï¼ŒåŒ…å« CPUã€å†…å­˜ã€ç£ç›˜ç­‰

```
Container = <NodeId, CPU cores, Memory, Priority, Token>

ç¤ºä¾‹ï¼š
Container_001:
  - Node: node1.example.com
  - CPU: 2 cores
  - Memory: 4GB
  - Priority: 5
```

### 4. YARN åº”ç”¨æ‰§è¡Œæµç¨‹

```mermaid
sequenceDiagram
    participant Client
    participant RM as ResourceManager
    participant NM as NodeManager
    participant AM as ApplicationMaster
    
    Client->>RM: 1. æäº¤åº”ç”¨ï¼ˆJAR + èµ„æºéœ€æ±‚ï¼‰
    RM->>NM: 2. é€‰æ‹©èŠ‚ç‚¹å¯åŠ¨ AM
    NM->>AM: 3. å¯åŠ¨ ApplicationMaster
    
    AM->>RM: 4. æ³¨å†Œè‡ªå·±
    AM->>RM: 5. ç”³è¯·èµ„æºï¼ˆContainer åˆ—è¡¨ï¼‰
    
    loop èµ„æºè°ƒåº¦
        Note over RM: 6. è°ƒåº¦å™¨åˆ†é…èµ„æº
        RM->>AM: 7. åˆ†é… Container
    end
    
    loop ä»»åŠ¡æ‰§è¡Œ
        AM->>NM: 8. å¯åŠ¨ Container
        NM->>NM: 9. æ‰§è¡Œä»»åŠ¡
        NM->>AM: 10. æŠ¥å‘Šè¿›åº¦
    end
    
    AM->>RM: 11. æ³¨é”€ï¼Œé‡Šæ”¾èµ„æº
    RM->>Client: 12. åº”ç”¨å®Œæˆ
```

---

## äº”ã€MapReduceï¼šåˆ†å¸ƒå¼è®¡ç®—æ¡†æ¶

### 1. MapReduce ç¼–ç¨‹æ¨¡å‹

MapReduce æ˜¯ä¸€ç§**ç¼–ç¨‹æ¨¡å‹**ï¼Œç”¨äºå¤„ç†å’Œç”Ÿæˆå¤§æ•°æ®é›†ã€‚

**æ ¸å¿ƒæ€æƒ³**ï¼šåˆ†è€Œæ²»ä¹‹ï¼ˆDivide and Conquerï¼‰

```mermaid
graph LR
    Input["å¤§æ•°æ®é›†"]
    
    subgraph MapPhase["Map Phase"]
        M1["Map Task 1"]
        M2["Map Task 2"]
        M3["Map Task N"]
    end
    
    subgraph ShufflePhase["Shuffle Phase"]
        S["åˆ†åŒºã€æ’åºã€åˆ†ç»„"]
    end
    
    subgraph ReducePhase["Reduce Phase"]
        R1["Reduce Task 1"]
        R2["Reduce Task 2"]
        R3["Reduce Task N"]
    end
    
    Output["ç»“æœ"]
    
    Input --> M1
    Input --> M2
    Input --> M3
    
    M1 --> S
    M2 --> S
    M3 --> S
    
    S --> R1
    S --> R2
    S --> R3
    
    R1 --> Output
    R2 --> Output
    R3 --> Output
```

### 2. ç»å…¸æ¡ˆä¾‹ï¼šWordCount

**éœ€æ±‚**ï¼šç»Ÿè®¡æ–‡æœ¬ä¸­æ¯ä¸ªå•è¯å‡ºç°çš„æ¬¡æ•°

**è¾“å…¥æ•°æ®**ï¼š
```
hello world
hello hadoop
hadoop mapreduce
```

**MapReduce å¤„ç†è¿‡ç¨‹**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input Split 1: "hello world"                                 â”‚
â”‚ Input Split 2: "hello hadoop"                                â”‚
â”‚ Input Split 3: "hadoop mapreduce"                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Map Phaseï¼ˆå¹¶è¡Œæ‰§è¡Œï¼‰                                          â”‚
â”‚                                                               â”‚
â”‚ Mapper 1: "hello world"                                      â”‚
â”‚   â†’ (hello, 1), (world, 1)                                   â”‚
â”‚                                                               â”‚
â”‚ Mapper 2: "hello hadoop"                                     â”‚
â”‚   â†’ (hello, 1), (hadoop, 1)                                  â”‚
â”‚                                                               â”‚
â”‚ Mapper 3: "hadoop mapreduce"                                 â”‚
â”‚   â†’ (hadoop, 1), (mapreduce, 1)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Shuffle & Sort Phaseï¼ˆåˆ†åŒºã€æ’åºã€åˆ†ç»„ï¼‰                        â”‚
â”‚                                                               â”‚
â”‚ Partition 1:                                                 â”‚
â”‚   hadoop â†’ [1, 1]                                            â”‚
â”‚   hello  â†’ [1, 1]                                            â”‚
â”‚                                                               â”‚
â”‚ Partition 2:                                                 â”‚
â”‚   mapreduce â†’ [1]                                            â”‚
â”‚   world     â†’ [1]                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Reduce Phaseï¼ˆå¹¶è¡Œèšåˆï¼‰                                       â”‚
â”‚                                                               â”‚
â”‚ Reducer 1:                                                   â”‚
â”‚   hadoop: [1, 1] â†’ (hadoop, 2)                               â”‚
â”‚   hello: [1, 1]  â†’ (hello, 2)                                â”‚
â”‚                                                               â”‚
â”‚ Reducer 2:                                                   â”‚
â”‚   mapreduce: [1] â†’ (mapreduce, 1)                            â”‚
â”‚   world: [1]     â†’ (world, 1)                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Output:                                                      â”‚
â”‚   hadoop      2                                              â”‚
â”‚   hello       2                                              â”‚
â”‚   mapreduce   1                                              â”‚
â”‚   world       1                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ä»£ç å®ç°**ï¼š

```java
// Mapper ç±»
public class WordCountMapper 
    extends Mapper<LongWritable, Text, Text, IntWritable> {
    
    private final static IntWritable one = new IntWritable(1);
    private Text word = new Text();
    
    @Override
    public void map(LongWritable key, Text value, Context context) 
        throws IOException, InterruptedException {
        
        String line = value.toString();
        String[] words = line.split("\\s+");
        
        for (String w : words) {
            word.set(w);
            context.write(word, one);  // è¾“å‡º (word, 1)
        }
    }
}

// Reducer ç±»
public class WordCountReducer 
    extends Reducer<Text, IntWritable, Text, IntWritable> {
    
    @Override
    public void reduce(Text key, Iterable<IntWritable> values, Context context) 
        throws IOException, InterruptedException {
        
        int sum = 0;
        for (IntWritable val : values) {
            sum += val.get();
        }
        
        context.write(key, new IntWritable(sum));  // è¾“å‡º (word, count)
    }
}

// Driver ç±»
public class WordCount {
    public static void main(String[] args) throws Exception {
        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf, "word count");
        
        job.setJarByClass(WordCount.class);
        job.setMapperClass(WordCountMapper.class);
        job.setReducerClass(WordCountReducer.class);
        
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);
        
        FileInputFormat.addInputPath(job, new Path(args[0]));
        FileOutputFormat.setOutputPath(job, new Path(args[1]));
        
        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}
```

### 3. MapReduce æ‰§è¡Œæµç¨‹ï¼ˆè¯¦ç»†ï¼‰

```mermaid
flowchart TB
    subgraph Row1["Map é˜¶æ®µ"]
        direction LR
        Input["è¾“å…¥ HDFS"] --> Read["è¯»å–æ•°æ®"] --> Split["åˆ‡åˆ† Split"] --> RR["RecordReader"] --> Map["Mapper.map"] --> Buffer["ç¯å½¢ç¼“å†²åŒº"]
    end
    
    subgraph Row2["Shuffle + Reduce é˜¶æ®µ"]
        direction LR
        Sort["æ’åº"] --> Partition["åˆ†åŒº"] --> Combine["Combiner"] --> Spill["æº¢å†™"] --> Merge["å½’å¹¶"] --> Copy["æ‹‰å–"] --> Reduce["Reducer"] --> Output["è¾“å‡º HDFS"]
    end
    
    Row1 --> Row2
```

---

## å…­ã€Hadoop ç”Ÿæ€ç³»ç»Ÿ

Hadoop æ ¸å¿ƒåªæ˜¯åŸºç¡€ï¼Œå›´ç»•å®ƒå½¢æˆäº†åºå¤§çš„ç”Ÿæ€ç³»ç»Ÿï¼š

```mermaid
graph TB
    subgraph DataCollection["æ•°æ®é‡‡é›†"]
        Flume["Flume<br/>æ—¥å¿—é‡‡é›†"]
        Sqoop["Sqoop<br/>æ•°æ®å¯¼å…¥å¯¼å‡º"]
        Kafka["Kafka<br/>æ¶ˆæ¯é˜Ÿåˆ—"]
    end
    
    subgraph DataStorage["æ•°æ®å­˜å‚¨"]
        HDFS["HDFS<br/>åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ"]
        HBase["HBase<br/>NoSQL æ•°æ®åº“"]
        Kudu["Kudu<br/>åˆ—å¼å­˜å‚¨"]
    end
    
    subgraph ResourceMgmt["èµ„æºç®¡ç†"]
        YARN["YARN<br/>èµ„æºè°ƒåº¦"]
    end
    
    subgraph DataCompute["æ•°æ®è®¡ç®—"]
        MapReduce["MapReduce<br/>æ‰¹å¤„ç†"]
        Spark["Spark<br/>å†…å­˜è®¡ç®—"]
        Flink["Flink<br/>æµè®¡ç®—"]
        Tez["Tez<br/>DAG å¼•æ“"]
    end
    
    subgraph DataAnalysis["æ•°æ®åˆ†æ"]
        Hive["Hive<br/>SQL on Hadoop"]
        Pig["Pig<br/>è„šæœ¬è¯­è¨€"]
        Impala["Impala<br/>å®æ—¶æŸ¥è¯¢"]
        Presto["Presto<br/>åˆ†å¸ƒå¼ SQL"]
    end
    
    subgraph TaskSchedule["ä»»åŠ¡è°ƒåº¦"]
        Oozie["Oozie<br/>å·¥ä½œæµ"]
        Azkaban["Azkaban<br/>ä»»åŠ¡è°ƒåº¦"]
    end
    
    subgraph ClusterMgmt["é›†ç¾¤ç®¡ç†"]
        Ambari["Ambari<br/>é›†ç¾¤éƒ¨ç½²ç›‘æ§"]
        ZooKeeper["ZooKeeper<br/>åè°ƒæœåŠ¡"]
    end
    
    Flume --> HDFS
    Sqoop --> HDFS
    Kafka --> HDFS
    
    YARN --> MapReduce
    YARN --> Spark
    YARN --> Flink
    YARN --> Tez
    
    HDFS --> Hive
    HDFS --> HBase
    HBase --> Hive
    
    Tez --> Hive
    
    ZooKeeper --> HBase
    ZooKeeper --> Kafka
```

### ä¸»è¦ç»„ä»¶åŠŸèƒ½å¯¹æ¯”

| ç»„ä»¶ | ç±»å‹ | æ ¸å¿ƒåŠŸèƒ½ | é€‚ç”¨åœºæ™¯ |
|------|------|----------|---------|
| **Hive** | SQL å¼•æ“ | å°† SQL è½¬æ¢ä¸º MapReduce/Tez | ç¦»çº¿æ•°æ®ä»“åº“ã€æ‰¹é‡åˆ†æ |
| **HBase** | NoSQL æ•°æ®åº“ | å®æ—¶è¯»å†™ã€åˆ—å¼å­˜å‚¨ | å®æ—¶æŸ¥è¯¢ã€æ—¶åºæ•°æ® |
| **Spark** | è®¡ç®—å¼•æ“ | å†…å­˜è®¡ç®—ã€DAG æ‰§è¡Œ | è¿­ä»£è®¡ç®—ã€æœºå™¨å­¦ä¹  |
| **Flink** | æµå¤„ç† | çœŸæ­£çš„æµè®¡ç®— | å®æ—¶æ•°æ®å¤„ç†ã€äº‹ä»¶å¤„ç† |
| **Flume** | æ•°æ®é‡‡é›† | æ—¥å¿—æ”¶é›†ã€ä¼ è¾“ | æ—¥å¿—èšåˆã€ETL |
| **Sqoop** | æ•°æ®åŒæ­¥ | RDBMS â†” Hadoop | æ•°æ®è¿ç§»ã€å¤‡ä»½ |
| **ZooKeeper** | åè°ƒæœåŠ¡ | é…ç½®ç®¡ç†ã€é€‰ä¸¾ | åˆ†å¸ƒå¼é”ã€NameNode HA |

---

## ä¸ƒã€Hadoop åº”ç”¨åœºæ™¯

### 1. å…¸å‹åº”ç”¨åœºæ™¯

| åœºæ™¯ | ä½¿ç”¨æŠ€æœ¯ | æ¡ˆä¾‹ |
|------|---------|------|
| **æ—¥å¿—åˆ†æ** | HDFS + MapReduce/Spark + Hive | ç½‘ç«™ç”¨æˆ·è¡Œä¸ºåˆ†æã€å¹¿å‘Šç‚¹å‡»åˆ†æ |
| **æ¨èç³»ç»Ÿ** | HDFS + Spark MLlib + HBase | ç”µå•†å•†å“æ¨èã€è§†é¢‘å†…å®¹æ¨è |
| **æ•°æ®ä»“åº“** | HDFS + Hive + Impala | ä¼ä¸š BI åˆ†æã€æŠ¥è¡¨ç”Ÿæˆ |
| **æœç´¢å¼•æ“** | HDFS + MapReduce + HBase + Solr | å…¨æ–‡æ£€ç´¢ã€å€’æ’ç´¢å¼•æ„å»º |
| **å®æ—¶è®¡ç®—** | Kafka + Flink + HBase | å®æ—¶ç›‘æ§ã€å®æ—¶é£æ§ |
| **æœºå™¨å­¦ä¹ ** | HDFS + Spark MLlib | åˆ†ç±»ã€èšç±»ã€ååŒè¿‡æ»¤ |

### 2. ä¼ä¸šå®è·µæ¡ˆä¾‹

#### æ¡ˆä¾‹ 1ï¼šæ·˜å®æœç´¢æ—¥å¿—åˆ†æ

```
æ•°æ®æµå‘ï¼š
ç”¨æˆ·è¡Œä¸º 
  â†’ Flume é‡‡é›† 
  â†’ Kafka ç¼“å†² 
  â†’ Spark Streaming å®æ—¶å¤„ç† 
  â†’ HBase å­˜å‚¨ 
  â†’ Hive ç¦»çº¿åˆ†æ 
  â†’ å¯è§†åŒ–æŠ¥è¡¨
```

#### æ¡ˆä¾‹ 2ï¼šæ¨èç³»ç»Ÿ

```
ç¦»çº¿è®­ç»ƒï¼š
HDFS å†å²æ•°æ® 
  â†’ Spark MLlib ååŒè¿‡æ»¤ 
  â†’ æ¨¡å‹è¾“å‡ºåˆ° HBase

åœ¨çº¿æœåŠ¡ï¼š
ç”¨æˆ·è¯·æ±‚ 
  â†’ HBase æŸ¥è¯¢æ¨èç»“æœ 
  â†’ è¿”å› Top-N æ¨è
```

---

## å…«ã€Hadoop ä¼˜ç¼ºç‚¹åˆ†æ

### ä¼˜åŠ¿

| ä¼˜åŠ¿ | è¯´æ˜ |
|------|------|
| âœ… **é«˜å¯é æ€§** | æ•°æ®å¤šå‰¯æœ¬ï¼Œè‡ªåŠ¨å®¹é”™ |
| âœ… **é«˜æ‰©å±•æ€§** | å¯æ‰©å±•åˆ°æ•°åƒèŠ‚ç‚¹ |
| âœ… **æˆæœ¬ä½** | åŸºäºå»‰ä»· x86 æœåŠ¡å™¨ |
| âœ… **ç”Ÿæ€ä¸°å¯Œ** | æ•°ç™¾ä¸ªå¼€æºé¡¹ç›®æ”¯æŒ |
| âœ… **å¼€æºå…è´¹** | Apache å¼€æºï¼Œç¤¾åŒºæ´»è·ƒ |

### å±€é™æ€§

| å±€é™æ€§ | è¯´æ˜ | è§£å†³æ–¹æ¡ˆ |
|--------|------|---------|
| âŒ **å°æ–‡ä»¶é—®é¢˜** | å¤§é‡å°æ–‡ä»¶æ¶ˆè€— NN å†…å­˜ | HAR å½’æ¡£ã€SequenceFile |
| âŒ **ä¸é€‚åˆä½å»¶è¿Ÿ** | MapReduce å¯åŠ¨æ…¢ | ä½¿ç”¨ Sparkã€Impala |
| âŒ **ä¸æ”¯æŒä¿®æ”¹** | åªèƒ½è¿½åŠ ï¼Œä¸èƒ½æ›´æ–° | ä½¿ç”¨ HBaseã€Kudu |
| âŒ **NameNode ç“¶é¢ˆ** | å•èŠ‚ç‚¹å†…å­˜é™åˆ¶ | Federationã€NameNode HA |
| âŒ **å­¦ä¹ æ›²çº¿é™¡** | ä½“ç³»å¤æ‚ï¼Œé…ç½®ç¹ç | ä½¿ç”¨ Ambariã€CDH/HDP å‘è¡Œç‰ˆ |

---

## ä¹ã€Hadoop ç‰ˆæœ¬æ¼”è¿›

```mermaid
timeline
    title Hadoop ç‰ˆæœ¬æ¼”è¿›å²
    2006 : Hadoop 0.1
         : é¦–ä¸ªç‰ˆæœ¬å‘å¸ƒ
    2008 : Hadoop æˆä¸º Apache é¡¶çº§é¡¹ç›®
         : 1.0 ç‰ˆæœ¬ç¨³å®š
    2012 : Hadoop 2.0
         : å¼•å…¥ YARN
         : NameNode HA
    2017 : Hadoop 3.0
         : EC çº åˆ ç 
         : æ”¯æŒ \u003e 2 å‰¯æœ¬æ•°
    2021 : Hadoop 3.3
         : æ›´å¥½çš„äº‘åŸç”Ÿæ”¯æŒ
```

### ä¸»è¦ç‰ˆæœ¬å¯¹æ¯”

| ç‰¹æ€§ | Hadoop 1.x | Hadoop 2.x | Hadoop 3.x |
|------|-----------|-----------|-----------|
| **YARN** | âŒ | âœ… | âœ… |
| **NameNode HA** | âŒ | âœ… | âœ… |
| **Federation** | âŒ | âœ… | âœ… |
| **çº åˆ ç  EC** | âŒ | âŒ | âœ… |
| **æœ€å°å‰¯æœ¬æ•°** | 3 | 3 | å¯é…ç½® |
| **æœ€å¤§èŠ‚ç‚¹æ•°** | ~4000 | ~10000 | ~10000+ |

> [!TIP]
> **ç”Ÿäº§ç¯å¢ƒæ¨è**
> 
> - æ–°é¡¹ç›®ï¼šç›´æ¥ä½¿ç”¨ **Hadoop 3.x**
> - å­˜é‡ç³»ç»Ÿï¼šè°¨æ…å‡çº§ï¼Œå……åˆ†æµ‹è¯•
> - äº‘ç¯å¢ƒï¼šè€ƒè™‘æ‰˜ç®¡æœåŠ¡ï¼ˆEMRã€HDInsightã€CDHï¼‰

---

## åã€å­¦ä¹ å»ºè®®ä¸å®è·µè·¯å¾„

### 1. å­¦ä¹ è·¯çº¿å›¾

```mermaid
flowchart TB
    subgraph Row1["ç†è®º + æ­å»º"]
        direction LR
        Start["ğŸš€ å¼€å§‹"] --> T1["åˆ†å¸ƒå¼åŸç†"] --> T2["Hadoopæ¶æ„"] --> T3["HDFS/YARN/MR"] --> E1["ä¼ªåˆ†å¸ƒå¼å®‰è£…"] --> E2["é›†ç¾¤æ­å»º"] --> E3["é…ç½®å‚æ•°"]
    end
    
    subgraph Row2["å®è·µ + è¿›é˜¶ + å®æˆ˜"]
        direction LR
        P1["HDFSå‘½ä»¤"] --> P2["Java API"] --> P3["MapReduce"] --> A1["æºç é˜…è¯»"] --> A2["æ€§èƒ½è°ƒä¼˜"] --> A3["ç”Ÿæ€ç»„ä»¶"] --> F1["é¡¹ç›®å¼€å‘"] --> F2["é—®é¢˜æ’æŸ¥"] --> F3["ğŸ† æ¶æ„è®¾è®¡"]
    end
    
    Row1 --> Row2
```

### 2. æ¨èèµ„æº

#### ğŸ“š å¿…è¯»ä¹¦ç±

1. **ã€ŠHadoop æƒå¨æŒ‡å—ã€‹**ï¼ˆç¬¬4ç‰ˆï¼‰- Tom White
   - è¢«èª‰ä¸º Hadoop "åœ£ç»"ï¼Œå…¨é¢æ·±å…¥

2. **ã€ŠHadoop æŠ€æœ¯å†…å¹•ã€‹**ï¼ˆæ·±å…¥è§£æ YARN æ¶æ„è®¾è®¡ä¸å®ç°åŸç†ï¼‰- è‘£è¥¿æˆ
   - æ·±å…¥æºç çº§åˆ«ï¼Œé€‚åˆè¿›é˜¶

3. **ã€Šå¤§æ•°æ®ï¼šäº’è”ç½‘å¤§è§„æ¨¡æ•°æ®æŒ–æ˜ä¸åˆ†å¸ƒå¼å¤„ç†ã€‹** - æ–¯å¦ç¦å¤§å­¦ç»å…¸æ•™æ

#### ğŸ”— åœ¨çº¿èµ„æº

- **å®˜æ–¹æ–‡æ¡£**ï¼šhttps://hadoop.apache.org/docs/
- **GitHub æºç **ï¼šhttps://github.com/apache/hadoop
- **Cloudera æ•™ç¨‹**ï¼šhttps://www.cloudera.com/tutorials.html

#### ğŸ’» å®è·µå»ºè®®

> [!IMPORTANT]
> **åŠ¨æ‰‹å®è·µæ¯”é˜…è¯»æ›´é‡è¦ï¼**
> 
> 1. å…ˆåœ¨æœ¬åœ°æ­å»ºä¼ªåˆ†å¸ƒå¼ç¯å¢ƒ
> 2. å®Œæˆè‡³å°‘ 10 ä¸ª MapReduce ç¨‹åº
> 3. é˜…è¯» NameNodeã€DataNode æ ¸å¿ƒæºç 
> 4. å‚ä¸å¼€æºç¤¾åŒºï¼Œæäº¤ PR

### 3. æºç é˜…è¯»å»ºè®®ï¼ˆåŸºäºæ‚¨çš„å·¥ä½œåŒºï¼‰

æ ¹æ®æ‚¨å½“å‰çš„ Hadoop æºç å·¥ä½œåŒºï¼Œæ¨èçš„é˜…è¯»è·¯å¾„ï¼š

#### ç¬¬ä¸€é˜¶æ®µï¼šHDFS æ ¸å¿ƒæµç¨‹

```
1. HDFS å®¢æˆ·ç«¯ API
   /hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/
   â”œâ”€â”€ DistributedFileSystem.java   # ç”¨æˆ·å…¥å£
   â””â”€â”€ DFSClient.java                # æ ¸å¿ƒå®ç°

2. NameNode æ ¸å¿ƒ
   /hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/
   â”œâ”€â”€ NameNode.java                 # ä¸»ç±»
   â”œâ”€â”€ FSNamesystem.java             # å‘½åç©ºé—´ç®¡ç†
   â””â”€â”€ FSDirectory.java              # ç›®å½•æ ‘

3. DataNode æ ¸å¿ƒ
   /hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/
   â”œâ”€â”€ DataNode.java                 # ä¸»ç±»
   â””â”€â”€ BlockManager.java             # å—ç®¡ç†
```

#### ç¬¬äºŒé˜¶æ®µï¼šYARN èµ„æºè°ƒåº¦

```
/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/
â”œâ”€â”€ hadoop-yarn-server-resourcemanager/    # ResourceManager
â”œâ”€â”€ hadoop-yarn-server-nodemanager/        # NodeManager
â””â”€â”€ hadoop-yarn-server-applicationmaster/  # ApplicationMaster
```

---

## åä¸€ã€æ€»ç»“

Hadoop ä½œä¸º**å¤§æ•°æ®æ—¶ä»£çš„åŸºçŸ³**,è™½ç„¶ä¸å†æ˜¯æœ€çƒ­é—¨çš„æŠ€æœ¯ï¼Œä½†å…¶è®¾è®¡æ€æƒ³å’Œæ¶æ„ç†å¿µä¾ç„¶æ·±åˆ»å½±å“ç€æ•´ä¸ªå¤§æ•°æ®ç”Ÿæ€ã€‚

### æ ¸å¿ƒè¦ç‚¹å›é¡¾

1. **HDFS**ï¼šè§£å†³æµ·é‡æ•°æ®**å­˜å‚¨**é—®é¢˜
   - NameNode/DataNode ä¸»ä»æ¶æ„
   - æ•°æ®å— + å¤šå‰¯æœ¬æœºåˆ¶
   - é€‚åˆå¤§æ–‡ä»¶é¡ºåºè¯»å†™

2. **YARN**ï¼šè§£å†³é›†ç¾¤**èµ„æºç®¡ç†**é—®é¢˜
   - ResourceManager/NodeManager æ¶æ„
   - æ”¯æŒå¤šç§è®¡ç®—æ¡†æ¶
   - çµæ´»çš„èµ„æºè°ƒåº¦ç­–ç•¥

3. **MapReduce**ï¼šè§£å†³å¤§æ•°æ®**è®¡ç®—**é—®é¢˜
   - åˆ†è€Œæ²»ä¹‹çš„ç¼–ç¨‹æ¨¡å‹
   - Map â†’ Shuffle â†’ Reduce
   - é€‚åˆç¦»çº¿æ‰¹å¤„ç†

4. **ç”Ÿæ€ç³»ç»Ÿ**ï¼šä¸°å¯Œçš„å·¥å…·é“¾
   - Hiveï¼ˆSQLï¼‰ã€HBaseï¼ˆNoSQLï¼‰
   - Sparkï¼ˆå†…å­˜è®¡ç®—ï¼‰ã€Flinkï¼ˆæµå¤„ç†ï¼‰
   - è¦†ç›–æ•°æ®é‡‡é›†ã€å­˜å‚¨ã€è®¡ç®—ã€åˆ†æå…¨é“¾è·¯

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨

- [ ] æ­å»ºæœ¬åœ° Hadoop ç¯å¢ƒï¼ˆä¼ªåˆ†å¸ƒå¼ï¼‰
- [ ] å®Œæˆ WordCount ç¤ºä¾‹ç¼–ç¨‹
- [ ] å­¦ä¹  HDFS å‘½ä»¤è¡Œæ“ä½œ
- [ ] é˜…è¯» NameNode/DataNode æºç 
- [ ] å­¦ä¹  Hive/HBase ç­‰ç”Ÿæ€ç»„ä»¶

---

**æœ¬æ–‡æ˜¯ Hadoop å®Œå…¨æŒ‡å—ç³»åˆ—çš„ç¬¬ä¸€ç¯‡**ï¼Œåç»­å°†æ·±å…¥è®²è§£ï¼š
- **ç¬¬äºŒç¯‡**ï¼šHDFS æºç æ·±åº¦è§£æï¼ˆNameNode å¯åŠ¨æµç¨‹ã€å†™å…¥æµç¨‹ï¼‰
- **ç¬¬ä¸‰ç¯‡**ï¼šYARN èµ„æºè°ƒåº¦æºç å‰–æ
- **ç¬¬å››ç¯‡**ï¼šMapReduce æ‰§è¡ŒåŸç†ä¸æ€§èƒ½ä¼˜åŒ–
- **ç¬¬äº”ç¯‡**ï¼šHadoop çº¿ä¸Šè¿ç»´ä¸æ•…éšœæ’æŸ¥

---

**å¦‚æœä½ è§‰å¾—æœ¬æ–‡æœ‰å¸®åŠ©ï¼Œæ¬¢è¿ç‚¹èµã€æ”¶è—ã€å…³æ³¨ï¼å¦‚æœ‰ä»»ä½•ç–‘é—®æˆ–å»ºè®®ï¼Œæ¬¢è¿åœ¨è¯„è®ºåŒºç•™è¨€äº¤æµï¼**

> ğŸ“§ **è”ç³»æ–¹å¼**ï¼šæ¬¢è¿é€šè¿‡ GitHub æˆ–é‚®ä»¶äº¤æµå¤§æ•°æ®æŠ€æœ¯
> 
> ğŸ”— **ç³»åˆ—æ›´æ–°**ï¼šè¯·æŒç»­å…³æ³¨æœ¬åšå®¢ï¼Œè·å–æœ€æ–°çš„ Hadoop æ·±åº¦è§£ææ–‡ç« 
